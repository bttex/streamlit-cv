from pathlib import Path
import streamlit as st
from PIL import Image
import requests
import os

# --- PATH SETTINGS ---
current_dir = Path(__file__).parent if "__file__" in locals() else Path.cwd()
css_file = current_dir / "styles" / "main.css"
resume_file_by_language = {
    "PortuguÃªs": current_dir / "assets" / "CV.pdf",
    "English": current_dir / "assets" / "CV_EN.pdf",
}
profile_pic = current_dir / "assets" / "profile-pic.png"

st.set_page_config(
    page_title="CV Digital | Bruno Teixeira", page_icon=":wave:", layout="centered"
)

NAME = {"PortuguÃªs": "Bruno Teixeira", "English": "Bruno Teixeira"}
DESCRIPTION = {
    "PortuguÃªs": "Engenheiro de Dados com experiÃªncia em pipelines de ETL, automaÃ§Ã£o e arquitetura analÃ­tica em nuvem, atuando principalmente com Google BigQuery (GCP) e provisionamento de servidores Linux em AWS EC2.",
    "English": "Data Engineer with experience in cloud-based ETL pipelines, analytics engineering, and data platform automation, primarily using Google BigQuery (GCP) and Linux server provisioning on AWS EC2.",
}

EMAIL = "itbttex@icloud.com"
SOCIAL_MEDIA = {
    "LinkedIn": "https://www.linkedin.com/in/bruno-teixeira-6b543a201/",
    "GitHub": "https://github.com/bttex",
}
PROJECTS = {
    "ğŸ† GitHub Tracker - Monitora o status de builds no GitHub Actions e novas releases de um repositÃ³rio": "https://github.com/bttex/github_tracker",
    "ğŸ† TNT Tracker - Automatiza o rastreamento de encomendas no portal da TNT Brasil": "https://github.com/bttex/tnt_tracker",
    "ğŸ† Telegram Bot - Um bot que faz web scraping e captura informaÃ§Ãµes de servidores": "https://github.com/bttex/telegrambot",
}

EXPERIENCE = {
    "PortuguÃªs": """
- âœ”ï¸ Graduando em CiÃªncia de Dados na Universidade Descomplica â€” Ago/2024 â€“ Presente
- âœ”ï¸ 5 anos de experiÃªncia profissional na Ã¡rea de dados
- âœ”ï¸ Forte atuaÃ§Ã£o em Engenharia de Dados com Python e SQL
- âœ”ï¸ ExperiÃªncia prÃ¡tica com Google BigQuery (GCP) como data warehouse analÃ­tico
- âœ”ï¸ Provisionamento e administraÃ§Ã£o de servidores Linux em AWS EC2
- âœ”ï¸ Background sÃ³lido em BI e consumo analÃ­tico (Power BI e Excel)
    """,
    "English": """
- âœ”ï¸ Bachelorâ€™s degree in Data Science in progress at Descomplica University â€” Aug/2024 â€“ Present
- âœ”ï¸ 5 years of professional experience in the data field
- âœ”ï¸ Strong background in Data Engineering using Python and SQL
- âœ”ï¸ Hands-on experience with Google BigQuery (GCP) as an analytical data warehouse
- âœ”ï¸ Linux server provisioning and administration on AWS EC2
- âœ”ï¸ Solid background in BI and analytics consumption (Power BI and Excel)
    """,
}


HARD_SKILLS = {
    "PortuguÃªs": """
- ğŸ‘©â€ğŸ’» ProgramaÃ§Ã£o & Dados: Python (Pandas, Scikit-learn, Streamlit), SQL
- ğŸ”„ Engenharia de Dados: ETL / ELT pipelines, automaÃ§Ã£o de workflows
- â˜ï¸ Cloud & Data Platforms: Google Cloud Platform (BigQuery), AWS EC2
- ğŸ§ Infraestrutura: Provisionamento e administraÃ§Ã£o de servidores Linux
- ğŸ“Š Analytics & BI (background): Power BI, Excel
- ğŸ—„ï¸ Bancos de Dados: BigQuery, PostgreSQL, MySQL, SQL Server
    """,
    "English": """
- ğŸ‘©â€ğŸ’» Programming & Data: Python (Pandas, Scikit-learn, Streamlit), SQL
- ğŸ”„ Data Engineering: ETL / ELT pipelines, workflow automation
- â˜ï¸ Cloud & Data Platforms: Google Cloud Platform (BigQuery), AWS EC2
- ğŸ§ Infrastructure: Linux server provisioning and administration
- ğŸ“Š Analytics & BI (background): Power BI, Excel
- ğŸ—„ï¸ Databases: BigQuery, PostgreSQL, MySQL, SQL Server
    """,
}


WORK_HISTORY = {
    "PortuguÃªs": [
        (
            "ğŸš§ Engenheiro de Dados | Vertex Digital",
            "01/2023 - Presente",
            """
- â–º Desenvolvimento e manutenÃ§Ã£o de pipelines de ETL utilizando Python e SQL, com dados armazenados no Google BigQuery.
- â–º OtimizaÃ§Ã£o de consultas e processos no BigQuery, gerando aproximadamente R$5.000 em economia anual.
- â–º AutomaÃ§Ã£o de ingestÃ£o e transformaÃ§Ã£o de dados para suporte a dashboards quase em tempo real.
- â–º Provisionamento e gerenciamento de servidores Linux em AWS EC2 para execuÃ§Ã£o de processos e aplicaÃ§Ãµes de dados.
- â–º Desenvolvimento de aplicaÃ§Ãµes analÃ­ticas em Streamlit e suporte a camadas analÃ­ticas consumidas por Power BI.
        """,
        ),
        (
            "ğŸš§ Analista de BI | MP Advogados",
            "11/2021 - 12/2022",
            """
- â–º ApuraÃ§Ã£o e anÃ¡lise de resultados corporativos.
- â–º ParticipaÃ§Ã£o em reuniÃµes com foco na melhoria de processos analÃ­ticos e operacionais.
- â–º Desenvolvimento de relatÃ³rios e dashboards em Power BI e Excel.
        """,
        ),
        (
            "ğŸš§ Assistente TÃ©cnico em BI | EletromecÃ¢nica do MaranhÃ£o",
            "01/2021 - 10/2021",
            """
- â–º Apoio Ã  tomada de decisÃ£o gerencial por meio da geraÃ§Ã£o de relatÃ³rios operacionais e financeiros.
- â–º Desenvolvimento e melhoria de processos internos para aumento de eficiÃªncia em Ã¡reas tÃ©cnicas.
- â–º ConsolidaÃ§Ã£o de pacotes de relatÃ³rios para anÃ¡lise de desempenho do negÃ³cio.
        """,
        ),
    ],
    "English": [
        (
            "ğŸš§ Data Engineer | Vertex Digital",
            "01/2023 - Present",
            """
- â–º Designed and maintained ETL pipelines using Python and SQL, with data stored and processed in Google BigQuery.
- â–º Optimized BigQuery queries and data workflows, generating approximately R$5,000 in annual cost savings.
- â–º Automated data ingestion and transformation to support near real-time analytics and dashboards.
- â–º Provisioned and managed Linux servers on AWS EC2 to run data pipelines and analytical applications.
- â–º Built analytical applications with Streamlit and supported analytics layers consumed by Power BI.
        """,
        ),
        (
            "ğŸš§ BI Analyst | MP Advogados",
            "11/2021 - 12/2022",
            """
- â–º Tracked and analyzed company performance metrics.
- â–º Participated in team discussions focused on improving analytical and operational processes.
- â–º Developed reports and dashboards using Power BI and Excel.
        """,
        ),
        (
            "ğŸš§ BI Technical Assistant | EletromecÃ¢nica do MaranhÃ£o",
            "01/2021 - 10/2021",
            """
- â–º Assisted managers in decision-making processes by producing operational and financial reports.
- â–º Developed and implemented internal processes to improve efficiency in technical areas.
- â–º Generated reporting packages for business performance analysis.
        """,
        ),
    ],
}


# --- LANGUAGE SELECTION ---
language = st.radio("Escolha o idioma / Choose language", ["PortuguÃªs", "English"])

selected_resume = resume_file_by_language[language]
# --- LOAD CSS, PDF & PROFILE PIC ---
with open(css_file) as f:
    st.markdown("<style>{}</style>".format(f.read()), unsafe_allow_html=True)
with open(selected_resume, "rb") as pdf_file:
    PDFbyte = pdf_file.read()
profile_pic = Image.open(profile_pic)

# --- HERO SECTION ---
col1, col2 = st.columns(2, gap="small")
with col1:
    st.image(profile_pic, width=230)

with col2:
    st.title(NAME[language])
    st.write(DESCRIPTION[language])
    st.download_button(
        label=" ğŸ“„ Download CV",
        data=PDFbyte,
        file_name=selected_resume.name,
        mime="application/octet-stream",
    )
    st.write("ğŸ“«", EMAIL)


# --- SOCIAL LINKS ---
st.write("\n")
cols = st.columns(len(SOCIAL_MEDIA))
for index, (platform, link) in enumerate(SOCIAL_MEDIA.items()):
    cols[index].write(f"[{platform}]({link})")


# --- EXPERIENCE & QUALIFICATIONS ---
st.write("\n")
st.subheader("ExperiÃªncia" if language == "PortuguÃªs" else "Experience")
st.write(EXPERIENCE[language])


# --- SKILLS ---
st.write("\n")
st.subheader("Hard Skills" if language == "PortuguÃªs" else "Hard Skills")
st.write(HARD_SKILLS[language])


# --- WORK HISTORY ---
st.write("\n")
st.subheader("HistÃ³rico" if language == "PortuguÃªs" else "Work History")
st.write("---")

for job_title, job_date, job_desc in WORK_HISTORY[language]:
    st.write(f"{job_title} ({job_date})")
    st.write(job_desc)

token = os.getenv("GITHUB_TOKEN")


def get_github_projects(username):
    token = os.getenv("GITHUB_TOKEN")
    headers = {"Authorization": f"token {token}"} if token else {}
    all_repos = []
    page = 1

    while True:
        url = f"https://api.github.com/users/{username}/repos?per_page=100&page={page}"
        response = requests.get(url, headers=headers)

        if response.status_code != 200:
            print("Erro na API:", response.status_code, response.text)
            return []

        repos = response.json()
        if not repos:
            break

        all_repos.extend(repos)
        page += 1

    return all_repos


# Mapeamento dos nomes dos repositÃ³rios para os nomes desejados
repo_name_mapping = {
    "telegrambot": {
        "PortuguÃªs": "Telegram Bot - Um bot que faz web scraping e captura informaÃ§Ãµes de servidores",
        "English": "Telegram Bot - A bot that does web scraping and captures server information",
    },
    "tnt_tracker": {
        "PortuguÃªs": "TNT Tracker - Automatiza o rastreamento de encomendas no portal da TNT Brasil",
        "English": "TNT Tracker - Automates package tracking on TNT Brasil portal",
    },
    "github_tracker": {
        "PortuguÃªs": "GitHub Tracker - Monitora o status de builds no GitHub Actions e novas releases de um repositÃ³rio",
        "English": "GitHub Tracker - Monitors build status on GitHub Actions and new releases of a repository",
    },
}


def get_normalized_name(repo_name, language):
    return repo_name_mapping.get(repo_name, {}).get(language, repo_name.capitalize())


# Seu nome de usuÃ¡rio no GitHub
github_username = "bttex"

# Obter os projetos
projects = get_github_projects(github_username)

# Filtrar os repositÃ³rios que vocÃª deseja exibir
desired_repositories = ["telegrambot", "tnt_tracker", "github_tracker"]
filtered_projects = [
    project for project in projects if project["name"] in desired_repositories
]
# --- Projects & Accomplishments ---
st.write("\n")
st.subheader("Projetos" if language == "PortuguÃªs" else "Projects")
st.write("---")
# Exibir os 3 primeiros projetos
# Exibir os projetos com os nomes normalizados
for project in filtered_projects[:3]:  # Limite para os 3 primeiros
    repo_name = project["name"]
    normalized_name = get_normalized_name(repo_name, language)
    repo_description = project.get("description", "Sem descriÃ§Ã£o")

    st.write(f"{normalized_name}")
    st.write(f"Link: {project['html_url']}")
    st.write("---")


st.write("\n")
st.subheader("Cursos" if language == "PortuguÃªs" else "Courses")
st.write("---")

col3, col4, col5 = st.columns(3, gap="small")
with col3:
    st.image(image="assets/introduction-to-cybersecurity.png")
with col4:
    st.image(image="assets/introduction-to-data-science.png")
with col5:
    st.image(image="assets/python-essentials-1.1.png")
